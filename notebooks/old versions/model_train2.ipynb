{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas numpy scikit-learn joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flood Risk Accuracy: 0.7716195816260514\n",
      "Flood Occurred Accuracy: 0.8000862626698296\n",
      "Area Affected RMSE: 0.8828201711439362\n",
      "Population Affected RMSE: 1.0437836455695564\n",
      "Damage to Crops RMSE: 1.020561167224183\n",
      "Damage to Houses RMSE: 1.0217082227446002\n",
      "Models saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"../data/cleaned_flood_data.csv\")  # Ensure the correct file path\n",
    "\n",
    "# Encode categorical variables (District, River)\n",
    "label_encoders = {}\n",
    "for col in [\"District\", \"River\"]:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le  # Save encoders for later use\n",
    "\n",
    "# Define input features (Include Month_sin and Month_cos)\n",
    "X = df[[\"River\", \"River Level\", \"Rainfall (mm)\", \"District\", \"Month_sin\", \"Month_cos\"]]\n",
    "\n",
    "# Classification targets\n",
    "y_flood_risk = df[\"Flood Risk\"].fillna(df[\"Flood Risk\"].mode()[0]).astype(int)\n",
    "y_flood_occurred = df[\"Flood Occurred\"].fillna(df[\"Flood Occurred\"].mode()[0]).astype(int)\n",
    "\n",
    "# Regression targets\n",
    "y_area_affected = df[\"Area affected in (m.ha)\"].fillna(df[\"Area affected in (m.ha)\"].median())\n",
    "y_population_affected = df[\"Population affected in (million)\"].fillna(df[\"Population affected in (million)\"].median())\n",
    "y_damage_crops = df[\"Damage to Crops\"].fillna(df[\"Damage to Crops\"].median())\n",
    "y_damage_houses = df[\"Damage to Houses\"].fillna(df[\"Damage to Houses\"].median())\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train_risk, y_test_risk = train_test_split(X, y_flood_risk, test_size=0.2, random_state=42)\n",
    "_, _, y_train_occurred, y_test_occurred = train_test_split(X, y_flood_occurred, test_size=0.2, random_state=42)\n",
    "_, _, y_train_area, y_test_area = train_test_split(X, y_area_affected, test_size=0.2, random_state=42)\n",
    "_, _, y_train_pop, y_test_pop = train_test_split(X, y_population_affected, test_size=0.2, random_state=42)\n",
    "_, _, y_train_crops, y_test_crops = train_test_split(X, y_damage_crops, test_size=0.2, random_state=42)\n",
    "_, _, y_train_houses, y_test_houses = train_test_split(X, y_damage_houses, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train classification models\n",
    "clf_risk = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf_risk.fit(X_train_scaled, y_train_risk)\n",
    "\n",
    "clf_occurred = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf_occurred.fit(X_train_scaled, y_train_occurred)\n",
    "\n",
    "# Train regression models\n",
    "reg_area = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "reg_area.fit(X_train_scaled, y_train_area)\n",
    "\n",
    "reg_pop = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "reg_pop.fit(X_train_scaled, y_train_pop)\n",
    "\n",
    "reg_crops = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "reg_crops.fit(X_train_scaled, y_train_crops)\n",
    "\n",
    "reg_houses = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "reg_houses.fit(X_train_scaled, y_train_houses)\n",
    "\n",
    "# Predictions\n",
    "y_pred_risk = clf_risk.predict(X_test_scaled)\n",
    "y_pred_occurred = clf_occurred.predict(X_test_scaled)\n",
    "y_pred_area = reg_area.predict(X_test_scaled)\n",
    "y_pred_pop = reg_pop.predict(X_test_scaled)\n",
    "y_pred_crops = reg_crops.predict(X_test_scaled)\n",
    "y_pred_houses = reg_houses.predict(X_test_scaled)\n",
    "\n",
    "# Model evaluation\n",
    "print(\"Flood Risk Accuracy:\", accuracy_score(y_test_risk, y_pred_risk))\n",
    "print(\"Flood Occurred Accuracy:\", accuracy_score(y_test_occurred, y_pred_occurred))\n",
    "print(\"Area Affected RMSE:\", np.sqrt(mean_squared_error(y_test_area, y_pred_area)))\n",
    "print(\"Population Affected RMSE:\", np.sqrt(mean_squared_error(y_test_pop, y_pred_pop)))\n",
    "print(\"Damage to Crops RMSE:\", np.sqrt(mean_squared_error(y_test_crops, y_pred_crops)))\n",
    "print(\"Damage to Houses RMSE:\", np.sqrt(mean_squared_error(y_test_houses, y_pred_houses)))\n",
    "\n",
    "# Save models\n",
    "joblib.dump(clf_risk, \"flood_risk_model.pkl\")\n",
    "joblib.dump(reg_area, \"area_affected_model.pkl\")\n",
    "joblib.dump(reg_pop, \"population_affected_model.pkl\")\n",
    "joblib.dump(reg_crops, \"damage_crops_model.pkl\")\n",
    "joblib.dump(reg_houses, \"damage_houses_model.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "joblib.dump(label_encoders, \"label_encoders.pkl\")  \n",
    "\n",
    "print(\"Models saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes in y_train_risk: [1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique classes in y_train_risk:\", np.unique(y_train_risk))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flood Risk Accuracy: 0.7948561862730178\n",
      "Area Affected RMSE: 0.9314020927503911\n",
      "Population Affected RMSE: 0.9033535327320438\n",
      "Damage to Crops RMSE: 0.8852296741132138\n",
      "Damage to Houses RMSE: 0.9328805196294667\n",
      "✅ Models and encoders saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "import joblib\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"../data/scaled_flood_data.csv\")\n",
    "\n",
    "# Drop 'Year' column if present\n",
    "df.drop(columns=[\"Year\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoder_district = LabelEncoder()\n",
    "label_encoder_river = LabelEncoder()\n",
    "\n",
    "df[\"District\"] = label_encoder_district.fit_transform(df[\"District\"])\n",
    "df[\"River\"] = label_encoder_river.fit_transform(df[\"River\"])\n",
    "\n",
    "# Feature Engineering (Interaction Terms)\n",
    "df[\"Rainfall × River Level\"] = df[\"Rainfall (mm)\"] * df[\"River Level\"]\n",
    "df[\"Rainfall × Month_sin\"] = df[\"Rainfall (mm)\"] * df[\"Month_sin\"]\n",
    "df[\"River Level × Month_cos\"] = df[\"River Level\"] * df[\"Month_cos\"]\n",
    "\n",
    "# Define feature columns\n",
    "X = df[[\n",
    "    \"River\", \"River Level\", \"Rainfall (mm)\", \"District\", \"Month_sin\", \"Month_cos\",\n",
    "    \"Rainfall × River Level\", \"Rainfall × Month_sin\", \"River Level × Month_cos\"\n",
    "]]\n",
    "\n",
    "# Define target variables\n",
    "y_flood_risk = df[\"Flood Risk\"].fillna(df[\"Flood Risk\"].mode()[0]).astype(int)\n",
    "y_area_affected = df[\"Area affected in (m.ha)\"].fillna(df[\"Area affected in (m.ha)\"].median())\n",
    "y_population_affected = df[\"Population affected in (million)\"].fillna(df[\"Population affected in (million)\"].median())\n",
    "y_damage_crops = df[\"Damage to Crops\"].fillna(df[\"Damage to Crops\"].median())\n",
    "y_damage_houses = df[\"Damage to Houses\"].fillna(df[\"Damage to Houses\"].median())\n",
    "\n",
    "# Split data (consistent splitting)\n",
    "X_train, X_test, y_train_risk, y_test_risk = train_test_split(X, y_flood_risk, test_size=0.2, random_state=42)\n",
    "_, _, y_train_area, y_test_area = train_test_split(X, y_area_affected, test_size=0.2, random_state=42)\n",
    "_, _, y_train_pop, y_test_pop = train_test_split(X, y_population_affected, test_size=0.2, random_state=42)\n",
    "_, _, y_train_crops, y_test_crops = train_test_split(X, y_damage_crops, test_size=0.2, random_state=42)\n",
    "_, _, y_train_houses, y_test_houses = train_test_split(X, y_damage_houses, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train classification model (Flood Risk)\n",
    "clf_risk = XGBClassifier(n_estimators=200, learning_rate=0.07, max_depth=6, random_state=42)\n",
    "clf_risk.fit(X_train_scaled, y_train_risk)\n",
    "\n",
    "# Train regression models\n",
    "reg_area = XGBRegressor(n_estimators=200, learning_rate=0.07, max_depth=6, random_state=42)\n",
    "reg_area.fit(X_train_scaled, y_train_area)\n",
    "\n",
    "reg_pop = XGBRegressor(n_estimators=200, learning_rate=0.07, max_depth=6, random_state=42)\n",
    "reg_pop.fit(X_train_scaled, y_train_pop)\n",
    "\n",
    "reg_crops = XGBRegressor(n_estimators=200, learning_rate=0.07, max_depth=6, random_state=42)\n",
    "reg_crops.fit(X_train_scaled, y_train_crops)\n",
    "\n",
    "reg_houses = XGBRegressor(n_estimators=200, learning_rate=0.07, max_depth=6, random_state=42)\n",
    "reg_houses.fit(X_train_scaled, y_train_houses)\n",
    "\n",
    "# Model evaluation\n",
    "print(\"Flood Risk Accuracy:\", accuracy_score(y_test_risk, clf_risk.predict(X_test_scaled)))\n",
    "print(\"Area Affected RMSE:\", np.sqrt(mean_squared_error(y_test_area, reg_area.predict(X_test_scaled))))\n",
    "print(\"Population Affected RMSE:\", np.sqrt(mean_squared_error(y_test_pop, reg_pop.predict(X_test_scaled))))\n",
    "print(\"Damage to Crops RMSE:\", np.sqrt(mean_squared_error(y_test_crops, reg_crops.predict(X_test_scaled))))\n",
    "print(\"Damage to Houses RMSE:\", np.sqrt(mean_squared_error(y_test_houses, reg_houses.predict(X_test_scaled))))\n",
    "\n",
    "# Save models and encoders\n",
    "joblib.dump(clf_risk, \"xgb_flood_risk_model.pkl\")\n",
    "joblib.dump(reg_area, \"xgb_area_affected_model.pkl\")\n",
    "joblib.dump(reg_pop, \"xgb_population_affected_model.pkl\")\n",
    "joblib.dump(reg_crops, \"xgb_damage_crops_model.pkl\")\n",
    "joblib.dump(reg_houses, \"xgb_damage_houses_model.pkl\")\n",
    "joblib.dump(scaler, \"xgb_scaler.pkl\")\n",
    "joblib.dump(label_encoder_district, \"label_encoder_district.pkl\")\n",
    "joblib.dump(label_encoder_river, \"label_encoder_river.pkl\")\n",
    "\n",
    "print(\"✅ Models and encoders saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature_names.pkl']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "import joblib\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"../data/cleaned_flood_data.csv\")\n",
    "\n",
    "# Define features and targets\n",
    "features = ['District', 'Rainfall (mm)', 'River', 'River Level',  'Month_sin', 'Month_cos']\n",
    "targets = {\n",
    "    'classification': ['Flood Risk'],\n",
    "    'regression': ['Area affected in (m.ha)', 'Population affected in (million)', \n",
    "                   'Damage to Crops', 'Damage to Houses']\n",
    "}\n",
    "\n",
    "# Prepare features\n",
    "X = df[features]\n",
    "\n",
    "# Save feature names for later use\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "# Handling missing values\n",
    "imputer = SimpleImputer(strategy=\"median\")  \n",
    "X = pd.DataFrame(imputer.fit_transform(X), columns=feature_names)\n",
    "\n",
    "# Standardizing features\n",
    "scaler_X = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler_X.fit_transform(X), columns=feature_names)\n",
    "\n",
    "# Prepare targets\n",
    "y_flood_risk = df[\"Flood Risk\"].fillna(df[\"Flood Risk\"].mode()[0]).astype(int)\n",
    "\n",
    "y_area = df[\"Area affected in (m.ha)\"].fillna(df[\"Area affected in (m.ha)\"].median())\n",
    "y_pop = df[\"Population affected in (million)\"].fillna(df[\"Population affected in (million)\"].median())\n",
    "y_crops = df[\"Damage to Crops\"].fillna(df[\"Damage to Crops\"].median())\n",
    "y_houses = df[\"Damage to Houses\"].fillna(df[\"Damage to Houses\"].median())\n",
    "\n",
    "# Standardize regression targets\n",
    "scaler_area = StandardScaler()\n",
    "scaler_pop = StandardScaler()\n",
    "scaler_crops = StandardScaler()\n",
    "scaler_houses = StandardScaler()\n",
    "\n",
    "y_area_scaled = scaler_area.fit_transform(y_area.values.reshape(-1, 1))\n",
    "y_pop_scaled = scaler_pop.fit_transform(y_pop.values.reshape(-1, 1))\n",
    "y_crops_scaled = scaler_crops.fit_transform(y_crops.values.reshape(-1, 1))\n",
    "y_houses_scaled = scaler_houses.fit_transform(y_houses.values.reshape(-1, 1))\n",
    "\n",
    "# Time-based splitting\n",
    "train_size = int(0.8 * len(df))\n",
    "X_train, X_test = X_scaled.iloc[:train_size], X_scaled.iloc[train_size:]\n",
    "\n",
    "# Split targets\n",
    "y_train_flood_risk, y_test_flood_risk = y_flood_risk.iloc[:train_size], y_flood_risk.iloc[train_size:]\n",
    "y_train_area, y_test_area = y_area.iloc[:train_size], y_area.iloc[train_size:]\n",
    "y_train_pop, y_test_pop = y_pop.iloc[:train_size], y_pop.iloc[train_size:]\n",
    "y_train_crops, y_test_crops = y_crops.iloc[:train_size], y_crops.iloc[train_size:]\n",
    "y_train_houses, y_test_houses = y_houses.iloc[:train_size], y_houses.iloc[train_size:]\n",
    "\n",
    "# Train models\n",
    "models = {\n",
    "    'flood_risk': XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=5),\n",
    "    'area': XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5),\n",
    "    'population': XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5),\n",
    "    'crops': XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5),\n",
    "    'houses': XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5)\n",
    "}\n",
    "\n",
    "models['flood_risk'].fit(X_train, y_train_flood_risk)\n",
    "models['area'].fit(X_train, y_train_area)\n",
    "models['population'].fit(X_train, y_train_pop)\n",
    "models['crops'].fit(X_train, y_train_crops)\n",
    "models['houses'].fit(X_train, y_train_houses)\n",
    "\n",
    "# Save models\n",
    "for name, model in models.items():\n",
    "    joblib.dump(model, f\"xgb_{name}.pkl\")\n",
    "\n",
    "# Save scalers and imputer\n",
    "joblib.dump(scaler_X, \"scaler_X.pkl\")\n",
    "joblib.dump(imputer, \"imputer.pkl\")\n",
    "joblib.dump(scaler_area, \"scaler_area.pkl\")\n",
    "joblib.dump(scaler_pop, \"scaler_pop.pkl\")\n",
    "joblib.dump(scaler_crops, \"scaler_crops.pkl\")\n",
    "joblib.dump(scaler_houses, \"scaler_houses.pkl\")\n",
    "\n",
    "# Save feature names\n",
    "joblib.dump(feature_names, \"feature_names.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Results:\n",
      "Flood Risk: 1 (0=No, 1=Yes, 2=Severe)\n",
      "Area affected: 0.51\n",
      "Population affected: -0.04\n",
      "Damage to Crops: -0.00\n",
      "Damage to Houses: -0.21\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load models\n",
    "models = {\n",
    "    'flood_risk': joblib.load(\"xgb_flood_risk.pkl\"),\n",
    "    \n",
    "    'area': joblib.load(\"xgb_area.pkl\"),\n",
    "    'population': joblib.load(\"xgb_population.pkl\"),\n",
    "    'crops': joblib.load(\"xgb_crops.pkl\"),\n",
    "    'houses': joblib.load(\"xgb_houses.pkl\")\n",
    "}\n",
    "\n",
    "# Load scalers and imputer\n",
    "scaler_X = joblib.load(\"scaler_X.pkl\")\n",
    "imputer = joblib.load(\"imputer.pkl\")\n",
    "scaler_area = joblib.load(\"scaler_area.pkl\")\n",
    "scaler_pop = joblib.load(\"scaler_pop.pkl\")\n",
    "scaler_crops = joblib.load(\"scaler_crops.pkl\")\n",
    "scaler_houses = joblib.load(\"scaler_houses.pkl\")\n",
    "\n",
    "# Load feature names\n",
    "feature_names = joblib.load(\"feature_names.pkl\")\n",
    "\n",
    "# Define new data sample (example values)\n",
    "X_new = pd.DataFrame([{\n",
    "    'District': 34,\n",
    "    'Rainfall (mm)': 5.5,\n",
    "    'River': 4,\n",
    "    'River Level': 3.5,\n",
    "    'Month_sin': 0.5,  \n",
    "    'Month_cos': 0.866  \n",
    "}])\n",
    "\n",
    "# Ensure all features are present and in correct order\n",
    "for feature in feature_names:\n",
    "    if feature not in X_new.columns:\n",
    "        X_new[feature] = 0\n",
    "X_new = X_new[feature_names]\n",
    "\n",
    "# Preprocess new data\n",
    "X_new_imputed = pd.DataFrame(imputer.transform(X_new), columns=feature_names)\n",
    "X_new_scaled = pd.DataFrame(scaler_X.transform(X_new_imputed), columns=feature_names)\n",
    "\n",
    "# Make predictions\n",
    "predictions = {\n",
    "    'Flood Risk': models['flood_risk'].predict(X_new_scaled)[0],\n",
    "    'Area affected': scaler_area.inverse_transform(\n",
    "        models['area'].predict(X_new_scaled).reshape(-1, 1))[0][0],\n",
    "    'Population affected': scaler_pop.inverse_transform(\n",
    "        models['population'].predict(X_new_scaled).reshape(-1, 1))[0][0],\n",
    "    'Damage to Crops': scaler_crops.inverse_transform(\n",
    "        models['crops'].predict(X_new_scaled).reshape(-1, 1))[0][0],\n",
    "    'Damage to Houses': scaler_houses.inverse_transform(\n",
    "        models['houses'].predict(X_new_scaled).reshape(-1, 1))[0][0]\n",
    "}\n",
    "\n",
    "# Display results\n",
    "print(\"Prediction Results:\")\n",
    "for target, value in predictions.items():\n",
    "    if target in ['Flood Risk']:\n",
    "        print(f\"{target}: {value} (0=No, 1=Yes, 2=Severe)\")\n",
    "    else:\n",
    "        print(f\"{target}: {value:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
