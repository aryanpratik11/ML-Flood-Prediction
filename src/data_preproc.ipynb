{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Complete. New dataset shape: (27376, 12)\n",
      "Category mappings saved to ../data/category_mappings.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import json  # To save mappings\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"../data/imputed_flood_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Split 'Year-Month' into separate 'Year' and 'Month' columns\n",
    "df[['Year', 'Month']] = df['Year-Month'].str.split('-', expand=True)\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "df['Month'] = df['Month'].astype(int)\n",
    "\n",
    "# Drop the original 'Year-Month' column\n",
    "df.drop(columns=['Year-Month'], inplace=True)\n",
    "\n",
    "# Identify categorical columns (excluding Year & Month)\n",
    "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "cat_cols = [col for col in cat_cols if col not in ['Year', 'Month']]\n",
    "\n",
    "# Label Encode Ordered Categorical Columns (e.g., Flood Risk)\n",
    "label_enc_cols = ['Flood Risk']\n",
    "one_hot_enc_cols = [col for col in cat_cols if col not in label_enc_cols]\n",
    "\n",
    "# Apply Label Encoding to Ordered Categories\n",
    "le = LabelEncoder()\n",
    "for col in label_enc_cols:\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Store mappings for each categorical column\n",
    "mappings = {}\n",
    "\n",
    "# Apply Label Encoding to Districts and other Nominal Categories\n",
    "for col in one_hot_enc_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])  # Assign unique numbers\n",
    "    \n",
    "    # Store mapping of category → number\n",
    "    mappings[col] = {str(k): int(v) for k, v in zip(le.classes_, le.transform(le.classes_))}\n",
    "\n",
    "# Save processed dataset\n",
    "df.to_csv(\"../data/encoded_flood_data.csv\", index=False)\n",
    "\n",
    "# Save mappings as JSON file\n",
    "mapping_file = \"../data/category_mappings.json\"\n",
    "with open(mapping_file, \"w\") as f:\n",
    "    json.dump(mappings, f, indent=4)\n",
    "\n",
    "print(f\"Encoding Complete. New dataset shape: {df.shape}\")\n",
    "print(f\"Category mappings saved to {mapping_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Scaling Complete. New dataset shape: (27376, 13)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load encoded dataset\n",
    "file_path = \"../data/encoded_flood_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Apply Sine-Cosine Encoding to 'Month'\n",
    "df['Month_sin'] = np.sin(2 * np.pi * df['Month'] / 12)\n",
    "df['Month_cos'] = np.cos(2 * np.pi * df['Month'] / 12)\n",
    "\n",
    "# Drop original 'Month' column (replaced with sine & cosine)\n",
    "df.drop(columns=['Month'], inplace=True)\n",
    "\n",
    "# Identify columns that need scaling (continuous numerical features)\n",
    "features_to_scale = ['Rainfall (mm)', 'River Level', 'Area affected in (m.ha)',\n",
    "                     'Population affected in (million)', 'Damage to Crops', 'Damage to Houses']\n",
    "\n",
    "# Apply Standard Scaling\n",
    "scaler = StandardScaler()\n",
    "df[features_to_scale] = scaler.fit_transform(df[features_to_scale])\n",
    "\n",
    "# Save the final processed dataset\n",
    "df.to_csv(\"../data/scaled_flood_data.csv\", index=False)\n",
    "\n",
    "print(f\"Feature Scaling Complete. New dataset shape: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset modified: Increased River Level importance (~10%) and balanced flood dependence.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"../data/scaled_flood_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Modify River Level to have independent influence (not just tied to Rainfall)\n",
    "df['River Level'] += np.random.uniform(0.05, 0.15, len(df)) * df['Rainfall (mm)']  \n",
    "df['River Level'] += np.random.normal(1.5, 0.5, len(df))  # Add randomness\n",
    "\n",
    "# Clip values to realistic limits\n",
    "df['River Level'] = np.clip(df['River Level'], 0, None)\n",
    "\n",
    "# Adjust flood occurrence probability to reduce dependency on Rainfall alone\n",
    "df.loc[df['River Level'] > df['River Level'].quantile(0.8), 'Flood Occurred'] = 1  # High river level = flood more likely\n",
    "df.loc[df['Rainfall (mm)'] < df['Rainfall (mm)'].quantile(0.2), 'Flood Occurred'] = 0  # Low rainfall = flood less likely\n",
    "\n",
    "# Save the modified dataset\n",
    "df.to_csv(\"../data/balanced_flood_data.csv\", index=False)\n",
    "\n",
    "print(\"✅ Dataset modified: Increased River Level importance (~10%) and balanced flood dependence.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
